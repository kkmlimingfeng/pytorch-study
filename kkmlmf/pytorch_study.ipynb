{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "125a186a-99b7-493e-aaca-3bac41862c17",
   "metadata": {},
   "source": [
    "# PyTorch入门"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25558d7-8931-446a-83dc-f14d6784976b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 检查torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9b850b20-68ec-4801-94dd-aed71a2f2694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 2.3.1+cu118\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: d:\\anaconda3\\envs\\yolov8\\lib\\site-packages\n",
      "Requires: filelock, fsspec, jinja2, mkl, networkx, sympy, typing-extensions\n",
      "Required-by: thop, torchaudio, torchvision, ultralytics, ultralytics-thop\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "95b97648-cc06-4b22-bb78-700de0662bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: einops\n",
      "Version: 0.8.1\n",
      "Summary: A new flavour of deep learning operations\n",
      "Home-page: \n",
      "Author: Alex Rogozhnikov\n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: d:\\anaconda3\\envs\\yolov8\\lib\\site-packages\n",
      "Requires: \n",
      "Required-by: \n",
      "---\n",
      "Name: tqdm\n",
      "Version: 4.66.4\n",
      "Summary: Fast, Extensible Progress Meter\n",
      "Home-page: \n",
      "Author: \n",
      "Author-email: \n",
      "License: MPL-2.0 AND MIT\n",
      "Location: d:\\anaconda3\\envs\\yolov8\\lib\\site-packages\n",
      "Requires: colorama\n",
      "Required-by: ultralytics\n"
     ]
    }
   ],
   "source": [
    "#拓展会用到的, 可以暂时不管\n",
    "!pip show einops tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2eb833c-9cca-4aff-945d-17cabb890a0c",
   "metadata": {},
   "source": [
    "按M切换markdown，按Y切换Code    \n",
    "按D+D删除一个块     \n",
    "按tab补全    \n",
    "按Shift+tab显示函数用法\n",
    "按Shift+Enter运行当前块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee3ad0f-3d07-4ecb-ab37-b9cb246265b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入torch包\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b701ec31-9e93-48d5-9d23-ccbbb8a8a18d",
   "metadata": {},
   "source": [
    "## 矩阵/张量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4ea793-7589-4afa-a79f-a643511db457",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 构造矩阵/张量\n",
    "构造一个5x3矩阵，不初始化 **torch.empty(5, 3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0301f6dc-5647-4ede-99ae-78c2f578e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5.8062e+25, 1.5120e-42, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53facbb9-e6cd-471b-b8be-b156c7dfa666",
   "metadata": {},
   "source": [
    "构造一个随机初始化的5x3矩阵 **torch.rand(5, 3)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d1d9565-33f3-47b1-a5ec-f17f29dde0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4846, 0.9098, 0.4612],\n",
      "        [0.9075, 0.4201, 0.8777],\n",
      "        [0.8954, 0.2958, 0.1461],\n",
      "        [0.4384, 0.0722, 0.1780],\n",
      "        [0.4325, 0.7753, 0.2879]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f2219-9cf5-4d8a-8b07-57f4e14d03c7",
   "metadata": {},
   "source": [
    "构造一个全0的5x3矩阵，指定数据类型是long **torch.zeros(5, 3, dtype=torch.long)**\n",
    "默认为float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2cffcc5e-639a-4416-8a86-9d70e2a053e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]),\n",
       " torch.int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)\n",
    "x, x.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25524610-dc2a-4259-898e-4bfabe6bfd5b",
   "metadata": {},
   "source": [
    "构造一个张量 **torch.tensor()** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa80a663-ead3-4347-aa13-84af740dd581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.5000, 3.0000]),\n",
       " tensor(5.5500),\n",
       " tensor([[1, 3],\n",
       "         [5, 7]]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([5.5, 3])\n",
    "y = torch.tensor(5.55)\n",
    "z = torch.tensor([[1,3],[5,7]])\n",
    "x, y, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7adbea44-e963-493c-adf8-7754052f707a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2]), torch.Size([]), torch.Size([2, 2]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(), y.size(), z.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856a81be-5bc2-4a20-a8c0-62aec86ed472",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 矩阵/张量 加减乘除\n",
    "add substract multiply divide remainder取余"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f4fbcfa-4333-4091-8217-950733bd14cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.5771, 1.0919, 1.6160],\n",
       "         [0.6953, 0.6703, 0.4160],\n",
       "         [1.2183, 1.5590, 1.3567],\n",
       "         [0.7859, 0.8927, 0.9204],\n",
       "         [1.8256, 1.6945, 0.5293]]),\n",
       " tensor([[0.5771, 1.0919, 1.6160],\n",
       "         [0.6953, 0.6703, 0.4160],\n",
       "         [1.2183, 1.5590, 1.3567],\n",
       "         [0.7859, 0.8927, 0.9204],\n",
       "         [1.8256, 1.6945, 0.5293]]),\n",
       " tensor([[0.5771, 1.0919, 1.6160],\n",
       "         [0.6953, 0.6703, 0.4160],\n",
       "         [1.2183, 1.5590, 1.3567],\n",
       "         [0.7859, 0.8927, 0.9204],\n",
       "         [1.8256, 1.6945, 0.5293]]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "y = torch.rand(5, 3)\n",
    "torch.add(x,y), x+y, y.add(x) #三种等价"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a22a18-49d5-43e4-ac4e-9e508567faf2",
   "metadata": {},
   "source": [
    "索引操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32b78394-5088-4837-883e-510f34c05138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4528, 0.6357, 0.7651, 0.3312, 0.9078])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e38b534-4cb9-4b74-b566-46e84721e5fb",
   "metadata": {},
   "source": [
    "改变大小：如果你想改变一个 tensor 的大小或者形状，你可以使用 **torch.view**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ef493e4-1a93-4268-881f-c7ea11885ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4]), torch.Size([16]), torch.Size([2, 8]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
    "x.size(), y.size(), z.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bbdb24-35bd-4d28-b0f8-6bd6c0349dfc",
   "metadata": {},
   "source": [
    "使用 .item() 来获得tensor的value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "197e0f2c-3d40-4d9c-af28-d368bf02061d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.8441]), torch.float32, 1.8440992832183838, float)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "x, x.dtype, x.item(), type(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131a10f4-3d59-4606-a081-dbfb606c0fa5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 拓展： Einops\n",
    "**rearrange**：张量维度重排 / 拆分 / 合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1f2da82-f3ed-4d0a-b79b-a2646be56b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f5b6d35-7766-43b3-93f2-afe7fd7a7793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d20a3f42-6b78-4738-9c4d-6477c6a0bfbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[9, 9, 3],\n",
       "          [2, 2, 7],\n",
       "          [2, 6, 5],\n",
       "          [3, 2, 8]],\n",
       " \n",
       "         [[9, 3, 6],\n",
       "          [4, 6, 2],\n",
       "          [9, 9, 9],\n",
       "          [9, 9, 3]]]),\n",
       " tensor([[[9, 2, 2, 3],\n",
       "          [9, 2, 6, 2],\n",
       "          [3, 7, 5, 8]],\n",
       " \n",
       "         [[9, 4, 9, 9],\n",
       "          [3, 6, 9, 9],\n",
       "          [6, 2, 9, 3]]]),\n",
       " tensor([[[[9, 9, 3],\n",
       "           [2, 2, 7]],\n",
       " \n",
       "          [[2, 6, 5],\n",
       "           [3, 2, 8]]],\n",
       " \n",
       " \n",
       "         [[[9, 3, 6],\n",
       "           [4, 6, 2]],\n",
       " \n",
       "          [[9, 9, 9],\n",
       "           [9, 9, 3]]]]),\n",
       " tensor([[9, 9, 3],\n",
       "         [2, 2, 7],\n",
       "         [2, 6, 5],\n",
       "         [3, 2, 8],\n",
       "         [9, 3, 6],\n",
       "         [4, 6, 2],\n",
       "         [9, 9, 9],\n",
       "         [9, 9, 3]]),\n",
       " torch.Size([2, 4, 3]),\n",
       " torch.Size([2, 3, 4]),\n",
       " torch.Size([2, 2, 2, 3]),\n",
       " torch.Size([8, 3]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(1, 10, (2, 4, 3)) \n",
    "# 示例1：维度转置（深度学习常用）\n",
    "x1 = einops.rearrange(x, 'b h c -> b c h')\n",
    "# 示例2：拆分维度（将height拆分为2段）\n",
    "x2 = einops.rearrange(x, 'b (h1 h2) c -> b h1 h2 c', h1=2)\n",
    "# 示例3：合并维度（合并batch和height）\n",
    "x3 = einops.rearrange(x, 'b h c -> (b h) c')\n",
    "x, x1, x2, x3, x.size(), x1.size(), x2.size(), x3.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4fd924-0187-42e4-9ad3-425322b8fd57",
   "metadata": {},
   "source": [
    "**reduce**：降维运算（求和 / 均值 / 最值等）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f243357-1d1d-41a4-a0ca-2e235fe0c447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[4, 1, 2, 7],\n",
       "          [6, 7, 7, 7],\n",
       "          [1, 4, 8, 2]],\n",
       " \n",
       "         [[3, 4, 5, 4],\n",
       "          [8, 1, 8, 5],\n",
       "          [1, 8, 2, 8]]]),\n",
       " tensor([[6, 7, 8, 7],\n",
       "         [8, 8, 8, 8]]),\n",
       " tensor([[ 7,  5,  7, 11],\n",
       "         [14,  8, 15, 12],\n",
       "         [ 2, 12, 10, 10]]),\n",
       " torch.Size([2, 3, 4]),\n",
       " torch.Size([2, 4]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(1, 10, (2, 3, 4))#1-10区间\n",
    "# 示例1：全局平均池化（NHWC → NC）\n",
    "x1 = einops.reduce(x, 'b h c -> b c', reduction='max')\n",
    "# 示例2：求和运算（可省略reduction，默认'sum'）\n",
    "x2 = einops.reduce(x, 'b h c -> h c', reduction='sum')\n",
    "x, x1, x2, x.size(), x1.size(), x2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2b9613a-e7b8-4524-aac0-f5cb26281c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.9435, 0.9011, 0.6886, 0.5216],\n",
       "          [0.4661, 0.2249, 0.7914, 0.5291],\n",
       "          [0.4664, 0.9044, 0.0911, 0.9349]],\n",
       " \n",
       "         [[0.0037, 0.8471, 0.5063, 0.7578],\n",
       "          [0.9693, 0.8180, 0.1576, 0.9940],\n",
       "          [0.0889, 0.1091, 0.1799, 0.2930]]]),\n",
       " tensor([[0.4736, 0.8741, 0.5975, 0.6397],\n",
       "         [0.7177, 0.5214, 0.4745, 0.7615],\n",
       "         [0.2776, 0.5068, 0.1355, 0.6140]]),\n",
       " torch.Size([2, 3, 4]),\n",
       " torch.Size([3, 4]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((2, 3, 4))\n",
    "# 示例3：按维度求最大值（保留height维度）\n",
    "x3 = einops.reduce(x, 'b h c -> h c', reduction='mean')\n",
    "x, x3, x.size(), x3.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f4e76d-4de5-4557-a8fb-dfc1b773b851",
   "metadata": {},
   "source": [
    "**repeat**：维度扩展（复制张量填充新维度）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "16cc2c46-dea1-4904-8a9b-d9c3b35235ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[8, 4],\n",
       "          [2, 3],\n",
       "          [6, 4]],\n",
       " \n",
       "         [[7, 4],\n",
       "          [2, 6],\n",
       "          [3, 9]]]),\n",
       " tensor([[[[8, 4],\n",
       "           [2, 3],\n",
       "           [6, 4]],\n",
       " \n",
       "          [[7, 4],\n",
       "           [2, 6],\n",
       "           [3, 9]]]]),\n",
       " tensor([[[8, 4],\n",
       "          [2, 3],\n",
       "          [6, 4],\n",
       "          [8, 4],\n",
       "          [2, 3],\n",
       "          [6, 4]],\n",
       " \n",
       "         [[7, 4],\n",
       "          [2, 6],\n",
       "          [3, 9],\n",
       "          [7, 4],\n",
       "          [2, 6],\n",
       "          [3, 9]]]),\n",
       " torch.Size([2, 3, 2]),\n",
       " torch.Size([1, 2, 3, 2]),\n",
       " torch.Size([2, 6, 2]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(1, 10, (2, 3, 2))  # [h,w,c]\n",
    "# 示例1：单张图片扩展为batch维度\n",
    "x1 = einops.repeat(x, 'h w c -> b h w c', b=1) \n",
    "# 示例2：在height维度复制2次\n",
    "x2 = einops.repeat(x, 'h w c -> h (repeat w) c', repeat=2)\n",
    "x, x1, x2, x.size(), x1.size(), x2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce407b-cc1f-4909-8a76-9b048187865a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 自动微分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f9be0a-c14e-4e85-9d86-e7a095217172",
   "metadata": {},
   "source": [
    "**autograd** 包是 PyTorch 中所有神经网络的核心。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30db827-cecf-43d4-92ee-4ef084c2e97e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 创建张量表达式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "52d17c8c-7af9-452b-8571-a094b65d1bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f0e1d9-572b-4bc0-a957-d83cca006e3b",
   "metadata": {},
   "source": [
    "创建一个张量，设置 requires_grad=True 来跟踪与它相关的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "00d3a148-fc24-4425-b1e1-779195563b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]], requires_grad=True),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.]], requires_grad=True))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "y = torch.ones(2, 2)\n",
    "y.requires_grad_(True)\n",
    "x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b6cf97-59a7-4326-9517-49e113a08fa7",
   "metadata": {},
   "source": [
    "针对张量做一个操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "87ee26cf-dd0b-4938-bd14-5d7815f7e3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 2.],\n",
       "         [2., 2.]], grad_fn=<AddBackward0>),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.]], grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 1\n",
    "w = x*x\n",
    "y, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6f848cc2-59c3-497a-a353-6b1c6aab0ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[8., 8.],\n",
       "         [8., 8.]], grad_fn=<MulBackward0>),\n",
       " tensor(8., grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = 2*y*y\n",
    "out = z.mean()\n",
    "z, out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8210ee8-c740-4087-9069-0121cb37a963",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 梯度，反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "909d570c-a4fd-4039-aec9-f8b24301cbfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dr.Weiss\\AppData\\Local\\Temp\\ipykernel_13364\\3983447777.py:6: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:494.)\n",
      "  out, z.grad, y.grad, x.grad\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(32., grad_fn=<SumBackward0>),\n",
       " None,\n",
       " None,\n",
       " tensor([[8., 8.],\n",
       "         [8., 8.]]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "y = x+1\n",
    "z = y*y*2\n",
    "out = z.sum()\n",
    "out.backward()\n",
    "out, z.grad, y.grad, x.grad\n",
    "#PyTorch 默认只会保留「叶子张量（leaf Tensor）」的梯度,所以第二个第三个输出为None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aa474882-2e19-4453-9afc-05efb0320c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(32., grad_fn=<SumBackward0>),\n",
       " tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " tensor([[8., 8.],\n",
       "         [8., 8.]]),\n",
       " tensor([[8., 8.],\n",
       "         [8., 8.]]))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)#1 x 4y x 1（y=x+1）\n",
    "y = x+1\n",
    "y.retain_grad()# 强制保留y的梯度:1 x 4y\n",
    "z = y*y*2\n",
    "z.retain_grad()# 强制保留z的梯度：1\n",
    "out = z.sum()\n",
    "out.backward()\n",
    "out, z.grad, y.grad, x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87bcf9f-1f61-4bd0-b5c5-2928032bbd6a",
   "metadata": {},
   "source": [
    "非标量求梯度方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "16115582-8f17-4369-aba9-049a97158009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6000, 6.0000, 0.0060])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(3, requires_grad=True)\n",
    "y = x * 2\n",
    "z = y * 3\n",
    "v = torch.tensor([0.1, 1, 0.001], dtype=torch.float)\n",
    "out = z.backward(v)\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9282599-b970-4a09-bd68-f99c8f2195f6",
   "metadata": {},
   "source": [
    "通过将代码包裹在 with torch.no_grad()，来停止对从跟踪历史中 的 .requires_grad=True 的张量自动求导。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "dd5bd9c9-e99c-47fa-b076-1f7764a76804",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4920a0-9b55-4f94-a083-113398ef31c9",
   "metadata": {},
   "source": [
    "## 神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e475684-f72e-4322-8060-520ae926e5e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 神经网络的经典结构层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48352b33-7c06-439a-9807-d976b03a89f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f836c1-58d5-479a-87e8-a691611eb4b0",
   "metadata": {},
   "source": [
    "**卷积层**： 一维卷积、二维卷积、三维卷积\n",
    "\n",
    "**必须参数**：输入通道数、输出通道数、卷积核大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "4d26c3f5-f0f4-421b-96ab-6f7259b8fb68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Conv1d(1, 5, kernel_size=(3,), stride=(1,)),\n",
       " Conv2d(1, 5, kernel_size=(3, 3), stride=(1, 1)),\n",
       " Conv3d(1, 5, kernel_size=(3, 3, 3), stride=(1, 1, 1)),\n",
       " ConvTranspose2d(1, 5, kernel_size=(3, 3), stride=(1, 1)))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channels = 1\n",
    "out_channels = 5\n",
    "kernel_size = 3  #等效 (3, 3) 或者(3, 3, 3)\n",
    "a = nn.Conv1d(in_channels, out_channels, kernel_size)\n",
    "b = nn.Conv2d(in_channels, out_channels, kernel_size)\n",
    "c = nn.Conv3d(in_channels, out_channels, kernel_size)\n",
    "d = nn.ConvTranspose2d(in_channels, out_channels, kernel_size)  #转置卷积\n",
    "a, b, c, d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f38727-3ea8-4d53-8b50-87239eab4f3f",
   "metadata": {},
   "source": [
    "**全连接层**\n",
    "\n",
    "**必须参数**: 输入特征数、输出特征数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f273deb7-ec1b-426e-bfeb-e8b47adb9a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=100, out_features=10, bias=True)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features = 100\n",
    "out_features = 10\n",
    "a = nn.Linear(in_features, out_features)\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3810f12-8b31-4c38-ae7f-697dca961761",
   "metadata": {},
   "source": [
    "**激活层**\n",
    "\n",
    "**必须参数**: 基本无，也可以传入一个网络层如conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4f2404f9-58e6-4bc0-a7b6-4db719f0ec06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-1.0358, -3.0907,  0.7388],\n",
       "         [-0.4331, -0.2649,  0.0335]]),\n",
       " tensor([[0.0000, 0.0000, 0.7388],\n",
       "         [0.0000, 0.0000, 0.0335]]),\n",
       " tensor([[0.1423, 0.0182, 0.8394],\n",
       "         [0.2647, 0.3132, 0.4221]]),\n",
       " tensor([[0.2620, 0.0435, 0.6767],\n",
       "         [0.3934, 0.4342, 0.5084]]),\n",
       " tensor([[-0.2713, -0.1344,  0.4999],\n",
       "         [-0.1704, -0.1150,  0.0170]]))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.ReLU(),    #最常用的 ReLU 激活，修正线性单元\n",
    "nn.Softmax(), #多分类任务输出层，将输出转为概率分布\n",
    "nn.Sigmoid(), #输出 0~1，多用于二分类输出层\n",
    "nn.GELU(),    #BERT 等 Transformer 模型的核心激活函数\n",
    "nn.SiLU()     #结合了ReLU和Sigmoid\n",
    "\n",
    "x = torch.randn(2, 3)\n",
    "a = F.relu(x)\n",
    "b = F.softmax(x, dim=1)\n",
    "c = F.sigmoid(x)\n",
    "d = F.silu(x)\n",
    "x, a, b, c, d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8757fdbc-d682-4391-a5b2-f7e9f582484d",
   "metadata": {},
   "source": [
    "**池化层**: 最大池化（下采样）、平均池化、自适应平均/最大池化、逆最大池化（上采样）\n",
    "\n",
    "**必须参数**: 池化核尺寸 或者 目标输出尺寸（自适应的用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f83b6a5b-a00d-47f8-ae3b-8788e2610b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False),\n",
       " AvgPool2d(kernel_size=3, stride=3, padding=0),\n",
       " AdaptiveAvgPool2d(output_size=3),\n",
       " MaxUnpool2d(kernel_size=(3, 3), stride=(3, 3), padding=(0, 0)))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "a = nn.MaxPool2d(kernel_size)\n",
    "b = nn.AvgPool2d(kernel_size)\n",
    "c = nn.AdaptiveAvgPool2d(kernel_size)\n",
    "d = nn.MaxUnpool2d(kernel_size)\n",
    "a, b, c, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5d1e02d2-8922-4fee-9a58-77f983c0f531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[7., 9., 7., 8., 4.],\n",
       "         [4., 9., 8., 3., 3.],\n",
       "         [7., 6., 4., 5., 9.],\n",
       "         [1., 9., 7., 6., 5.],\n",
       "         [3., 8., 4., 1., 2.]]),\n",
       " tensor([[9., 9., 8.],\n",
       "         [9., 9., 8.],\n",
       "         [7., 6., 9.],\n",
       "         [9., 9., 7.],\n",
       "         [8., 8., 4.]]),\n",
       " tensor([[0., 9., 0., 8., 0.],\n",
       "         [0., 9., 8., 0., 0.],\n",
       "         [7., 6., 0., 0., 9.],\n",
       "         [0., 9., 7., 0., 0.],\n",
       "         [0., 8., 4., 0., 0.]]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randint(1, 10, (5,5)).float()\n",
    "kernel_size = 3\n",
    "a, indices = F.max_pool1d(x, kernel_size, stride=1, return_indices=True)\n",
    "b = F.max_unpool1d(a, indices, kernel_size, stride=1)\n",
    "x, a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47948005-909f-4bb8-94db-89ded97466d1",
   "metadata": {},
   "source": [
    "**归一化层**：加速模型训练、缓解梯度消失，提升稳定性：批量归一化、层归一化、分组归一化、\n",
    "\n",
    "**必须参数**：通道数或特征数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "547265e7-f530-46d3-b48d-58745fcdba3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
       " LayerNorm((10, 10), eps=1e-05, elementwise_affine=True),\n",
       " GroupNorm(2, 10, eps=1e-05, affine=True))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.BatchNorm2d(num_features=10)\n",
    "b = nn.LayerNorm(normalized_shape=[10, 10]) #归一化的维度形状\n",
    "c = nn.GroupNorm(num_groups=2, num_channels=10)#分组数 和 输入通道数\n",
    "a, b, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0cde3d-f48c-4e12-b730-2091501323ab",
   "metadata": {},
   "source": [
    "**Dropout 层（正则化）**:\n",
    "\n",
    "**必须参数**：神经元丢弃概率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e4f00a63-acb5-45bd-84ee-9e86a1aafd41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.5, inplace=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Dropout(p = 0.5)#默认为0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09a15a4-726e-4097-b737-fe4eafa92dd5",
   "metadata": {},
   "source": [
    "**展平层**: 展平特征成一维\n",
    "\n",
    "**必须参数**：无"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "bb49db0c-d05a-4603-b29d-9f730fa25d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flatten(start_dim=1, end_dim=-1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac772e6-6659-4e61-a51b-3a7129c66ea1",
   "metadata": {},
   "source": [
    "**注意力机制层**：Transformer相关\n",
    "\n",
    "完整Transformer     d_model 模型维度默认512， nhead注意力头数默认8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4e8bbf8e-18bd-43c0-beb6-523b216a4dd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (decoder): TransformerDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerDecoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (multihead_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Transformer() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee95594-549e-4237-8ab5-06a192b09fae",
   "metadata": {},
   "source": [
    "多头自注意力层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aab83e48-11d0-4fc3-a834-725ae3b6feaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiheadAttention(\n",
       "  (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MultiheadAttention(embed_dim=512, num_heads=8)#输入嵌入维度 和 注意力头数（需能被 embed_dim 整除）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177ee5f5-962f-4ce0-b357-7b0ffadc9cb6",
   "metadata": {},
   "source": [
    "编码器层 和 编码器模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "94c88b26-5a1b-4bda-93ca-003ad1036307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TransformerEncoderLayer(\n",
       "   (self_attn): MultiheadAttention(\n",
       "     (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "   )\n",
       "   (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (dropout1): Dropout(p=0.1, inplace=False)\n",
       "   (dropout2): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " TransformerEncoder(\n",
       "   (layers): ModuleList(\n",
       "     (0-9): 10 x TransformerEncoderLayer(\n",
       "       (self_attn): MultiheadAttention(\n",
       "         (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "       )\n",
       "       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "       (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "       (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "       (dropout1): Dropout(p=0.1, inplace=False)\n",
       "       (dropout2): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.TransformerEncoderLayer(d_model=512, nhead=8)\n",
    "b = nn.TransformerEncoder(num_layers=10, encoder_layer=a) # 10层\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82024822-b9f1-4214-818c-f3c171447549",
   "metadata": {},
   "source": [
    "解码器层 和 解码器模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb5ca2fc-7b24-42e8-a211-3ddebb556665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TransformerDecoderLayer(\n",
       "   (self_attn): MultiheadAttention(\n",
       "     (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "   )\n",
       "   (multihead_attn): MultiheadAttention(\n",
       "     (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "   )\n",
       "   (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "   (dropout): Dropout(p=0.1, inplace=False)\n",
       "   (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "   (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (dropout1): Dropout(p=0.1, inplace=False)\n",
       "   (dropout2): Dropout(p=0.1, inplace=False)\n",
       "   (dropout3): Dropout(p=0.1, inplace=False)\n",
       " ),\n",
       " TransformerDecoder(\n",
       "   (layers): ModuleList(\n",
       "     (0-4): 5 x TransformerDecoderLayer(\n",
       "       (self_attn): MultiheadAttention(\n",
       "         (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "       )\n",
       "       (multihead_attn): MultiheadAttention(\n",
       "         (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "       )\n",
       "       (linear1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "       (dropout): Dropout(p=0.1, inplace=False)\n",
       "       (linear2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "       (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "       (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "       (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "       (dropout1): Dropout(p=0.1, inplace=False)\n",
       "       (dropout2): Dropout(p=0.1, inplace=False)\n",
       "       (dropout3): Dropout(p=0.1, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = nn.TransformerDecoderLayer(d_model=512, nhead=8)\n",
    "b = nn.TransformerDecoder(num_layers=5, decoder_layer=a) #5层\n",
    "a, b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e96c75c-7602-428d-b405-1d3bbe6f02ea",
   "metadata": {},
   "source": [
    "**损失函数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e5be544f-f06a-44a5-a796-80931fd57d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.MSELoss()          #均方误差损失（回归任务）\n",
    "nn.BCELoss()          #二分类交叉熵损失（二分类任务）\n",
    "nn.NLLLoss()          #负对数似然损失\n",
    "nn.CrossEntropyLoss() #交叉熵损失（多分类任务）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a97a12-5235-4a73-afaa-06c4af617853",
   "metadata": {},
   "source": [
    "**优化器**：根据反向传播得到的 “损失函数对参数的梯度”，按照特定策略自动更新模型的可学习参数\n",
    "\n",
    "**必须参数**：net.parameters(), 学习率lr 默认0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2142674a-c738-4055-85a5-fb04903056c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RMSprop (\n",
       "Parameter Group 0\n",
       "    alpha: 0.99\n",
       "    centered: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), \n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "optim.SGD(net.parameters(), lr=0.001)                 #随机梯度下降\n",
    "optim.SGD(net.parameters(), lr=0.001, momentum=0.9)   #带动量的随机梯度下降（惯性）\n",
    "optim.Adam(net.parameters(), lr=0.001)                #深度学习主流，权重衰减默认0\n",
    "optim.AdamW(net.parameters(), lr=0.001)               #Adam改进版，权重衰减默认0.01（正则化）\n",
    "optim.RMSprop(net.parameters(), lr=0.01)              #均方根传播，用于时序任务, lr默认0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eac0aff-599d-4b7b-abcb-4d33a3ef91a2",
   "metadata": {},
   "source": [
    "**其他不常用或过时网络层**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3930d5-a3e0-44d2-91e7-5994da2b594f",
   "metadata": {},
   "source": [
    "nn.RNN  循环神经网络\n",
    "\n",
    "nn.LSTM 长短期记忆网络\n",
    " \n",
    "nn.GRU 门控循环单元"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a65dda4-e186-4aff-8de2-fc3cc1f677eb",
   "metadata": {},
   "source": [
    "**神经网络顺序堆叠器**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2faf98c0-05b1-4496-885b-0aa9f4ceab2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (1): Sigmoid()\n",
       "  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): Sigmoid()\n",
       "  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (8): Sigmoid()\n",
       "  (9): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (10): Sigmoid()\n",
       "  (11): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(      #顺序堆叠网络的结构\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), \n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), \n",
    "    nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), \n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), \n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(84, 10)\n",
    ")\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d7a624-abbb-426f-89d8-a28124b2ac8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 简单神经网络测试\n",
    "**一个典型的神经网络训练过程包括以下几点：**\n",
    "\n",
    "**1.定义一个包含可训练参数的神经网络**\n",
    "\n",
    "**2.迭代整个输入**\n",
    "\n",
    "**3.通过神经网络处理输入**\n",
    "\n",
    "**4.计算损失(loss)**\n",
    "\n",
    "**5.反向传播梯度到神经网络的参数**\n",
    "\n",
    "**6.更新网络的参数，典型的用一个简单的更新方法：weight = weight - learning_rate \\*gradient**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a8b3cc-73e5-4012-b6d8-49e002fb3de5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **1、定义一个神经网络**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "998b18da-417d-4808-bf0d-ab4d870b49b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d( F.relu( self.conv1(x) ), (2, 2) )\n",
    "        x = F.max_pool2d( F.relu( self.conv2(x) ), 2 )\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu( self.fc1(x) )\n",
    "        x = F.relu( self.fc2(x) )\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "net = Net()\n",
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55258485-8a86-4ccb-80da-edc25a6b85c8",
   "metadata": {},
   "source": [
    "获取参数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccaa585d-e5a9-4c96-85a2-64cdb10e6d6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, torch.Size([6, 1, 5, 5]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters())\n",
    "len(params), params[0].size() # conv1's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f0fce5-0ea1-4e15-b985-b5bc0fe983bd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **2、创建一个输入 3、用神经网络处理输入**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5b13a81-6d02-4835-a94e-224e85f4125d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0276,  0.0138, -0.0138,  0.0147,  0.0652,  0.1065,  0.0360, -0.0031,\n",
       "           0.0333,  0.0173]], grad_fn=<AddmmBackward0>),\n",
       " torch.Size([1, 10]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randn(1, 1, 32, 32)\n",
    "out = net(input)\n",
    "out, out.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5a782-7386-4cbd-9fa8-842922ae981a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **4.计算损失(loss)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "528f5a43-39e4-4aff-bdaa-32db8ba59516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4764, grad_fn=<MseLossBackward0>), torch.Size([]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建一个目标值用于计算损失\n",
    "target = torch.randn(10)  # a dummy target, for example\n",
    "target = target.view(1, -1)  # make it the same shape as output\n",
    "#选择损失函数\n",
    "criterion = nn.MSELoss()\n",
    "#计算损失\n",
    "loss = criterion(out, target)\n",
    "loss, loss.size()#损失值是个标量"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad9c968-b5c9-469d-a039-d339070a4c0d",
   "metadata": {},
   "source": [
    "获取损失的反向传播路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38dd7d53-83a2-4cd4-b7ee-80c9dcca3ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward0 object at 0x00000212113633A0>\n",
      "<AddmmBackward0 object at 0x0000021211363BE0>\n",
      "<AccumulateGrad object at 0x00000212113633A0>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn)  # MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0])  # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0])  # ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2b1f1-bb8a-4b4c-af87-e2e2f84152c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **5.反向传播梯度到神经网络的参数**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "917ed1b4-68f4-43d6-966c-f8ea091d1e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0015, -0.0029,  0.0003, -0.0066,  0.0057,  0.0079])\n"
     ]
    }
   ],
   "source": [
    "# 梯度归零\n",
    "net.zero_grad()\n",
    "# 对损失值反向传播\n",
    "loss.backward()\n",
    "#查看第一层的梯度（默认只保存第一层的）\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b25ff8d-3f8d-4677-a5ee-5070484274d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **6.更新网络的参数**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb428ee0-fdde-4e1f-9643-53c00cf6fe87",
   "metadata": {},
   "source": [
    "最简单的更新规则就是随机梯度下降。\n",
    "\n",
    "weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79e3ca00-ea14-420f-9c29-44882a2ec241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学习率，小幅度更新梯度\n",
    "learning_rate = 0.1\n",
    "#梯度：让损失变大的方向，因此向反方向更新梯度\n",
    "#每一层的参数更新 = 每一层的参数 - 学习率*梯度\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21160444-1b4f-43be-b6e3-ac865783e2c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.4764, grad_fn=<MseLossBackward0>),\n",
       " tensor(0.4345, grad_fn=<MseLossBackward0>))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#观察参数更新后的损失变化\n",
    "out = net(input)\n",
    "loss2 = criterion(out, target)\n",
    "loss, loss2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f7d62-d363-4db5-ab08-a4f801e63bd8",
   "metadata": {},
   "source": [
    "可以观察到损失比更新前下降了"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2436241-8d8b-4fb4-8b1b-0459b455d21e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **总结训练步骤**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "264af544-902b-4f96-91b8-72f0fea781eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use device: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#自动选择GPU/CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"use device: {device}\")\n",
    "\n",
    "#初始化核心组件:神经网络、损失函数、优化器\n",
    "net = Net().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "#训练轮次、输入（train-dataset的x）、目标（train-dataset的y）\n",
    "epochs = 10\n",
    "inputs = torch.randn(1, 1, 32, 32).to(device)\n",
    "targets = torch.randn(10).view(1, 10).to(device)\n",
    "\n",
    "#切换训练模式\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8bcf74df-f5c3-49d9-be72-1b685ba6cd2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Loss: 0.7424\n",
      "Epoch [10/10], Loss: 0.6998\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    #训练循环内\n",
    "    optimizer.zero_grad()            #优化器梯度归零\n",
    "    output = net(inputs)              #前向传播\n",
    "    loss = criterion(output, targets) #计算损失\n",
    "    loss.backward()                  #反向传播\n",
    "    optimizer.step()                 #优化器更新参数\n",
    "    if (epoch + 1) % 5 == 0:  # 每5轮打印一次，避免日志刷屏\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "#训练完成：可选保存模型\n",
    "# torch.save(net.state_dict(), \"trained_model.pth\")\n",
    "# print(\"训练完成，模型已保存为 trained_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163df92d-e7fe-4b6c-8a99-60f478437e8b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 拓展：tqdm（训练时显示进度条）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "997de13e-40c1-457e-97e5-29f90ff97aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "64c52b29-924e-4276-94a8-95e89040d107",
   "metadata": {},
   "outputs": [],
   "source": [
    "#可接着直接运行\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "40b0a5e8-6e85-4501-93af-67f47ea8744e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度: 100%|██████████| 10/10 [00:10<00:00,  1.01s/it, Loss=0.5799]\n"
     ]
    }
   ],
   "source": [
    "def train_epochs_tqdm(epochs, net, optimizer, criterion, inputs, targets,wait_time=1):\n",
    "    pbar = tqdm(range(epochs), desc=\"训练进度\")\n",
    "    for epoch in pbar:\n",
    "        #训练循环内\n",
    "        optimizer.zero_grad()            #优化器梯度归零\n",
    "        output = net(inputs)              #前向传播\n",
    "        loss = criterion(output, targets) #计算损失\n",
    "        loss.backward()                  #反向传播\n",
    "        optimizer.step()                 #优化器更新参数\n",
    "        pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "        time.sleep(wait_time) #等 1 秒\n",
    "\n",
    "train_epochs_tqdm(epochs, net, optimizer, criterion, inputs, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c701a64-ee03-4607-b171-6faa0be69ce5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 拓展：Dataset、DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e3c78799-6f9d-40cf-95ca-3a1f11b17a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b7e2c557-d2b9-4a75-8ca5-2d4c66f4c139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use device: cuda\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, inputs, targets):\n",
    "        self.inputs = inputs\n",
    "        self.targets = targets\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        input = self.inputs[index]\n",
    "        target = self.targets[index]\n",
    "        return input, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "#==========================其他和前面一样==========================\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"use device: {device}\")\n",
    "net = Net().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "epochs = 100\n",
    "#=================================================================\n",
    "\n",
    "#划分数据集\n",
    "num_samples = 1000\n",
    "inputs = torch.randn(num_samples, 1, 32, 32)\n",
    "targets = torch.randn(num_samples, 10)\n",
    "train_size = int(0.8*num_samples)\n",
    "val_size = int(0.2*num_samples)\n",
    "\n",
    "#train and validation\n",
    "train_inputs = inputs[:train_size]\n",
    "train_targets = targets[:train_size]\n",
    "val_inputs = inputs[val_size:]\n",
    "val_targets = targets[val_size:]\n",
    "\n",
    "train_dataset = MyDataset(inputs=train_inputs, targets=train_targets)\n",
    "val_dataset = MyDataset(inputs=val_inputs, targets=val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8d9ad645-8d34-40e0-ad42-a8ce43387632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# 固定随机种子（保证实验可复现）\n",
    "def set_seed(seed=3407):            #3407 is all you need!\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9e70d8b1-45a5-4656-83e6-741f12ad97de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchsize=200:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练+验证进度: 100%|██████████| 100/100 [00:03<00:00, 31.35it/s, Train Loss=平均训练损失1.0269, Val Loss=平均验证损失1.0100]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchsize=100:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练+验证进度: 100%|██████████| 100/100 [00:04<00:00, 21.66it/s, Train Loss=平均训练损失1.0252, Val Loss=平均验证损失1.0092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchsize=50:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练+验证进度: 100%|██████████| 100/100 [00:07<00:00, 13.33it/s, Train Loss=平均训练损失1.0219, Val Loss=平均验证损失1.0066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchsize=10:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练+验证进度: 100%|██████████| 100/100 [00:33<00:00,  3.00it/s, Train Loss=平均训练损失0.6577, Val Loss=平均验证损失0.7691]\n"
     ]
    }
   ],
   "source": [
    "def different_batch_zize_train(batch_size):\n",
    "    #创建dataloader\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,  # 打乱数据（重要，避免过拟合）\n",
    "        drop_last=True  # 丢弃最后不足一个batch的样本（可选）\n",
    "    )\n",
    "    val_dataloader = DataLoader(\n",
    "        dataset=val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # 验证集无需打乱\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    #重新加载神经网络、损失函数、优化器\n",
    "    net = Net().to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "    \n",
    "    pbar = tqdm(range(epochs), desc=\"训练+验证进度\")\n",
    "    for epoch in pbar:\n",
    "        # ---------------------- 训练阶段 ----------------------\n",
    "        net.train()  # 切换训练模式（开启Dropout/BatchNorm训练）\n",
    "        train_loss = 0.0\n",
    "        for batch_input, batch_target in train_dataloader:\n",
    "            batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = net(batch_input)\n",
    "            loss = criterion(output, batch_target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * batch_size\n",
    "    \n",
    "        # 计算本轮训练平均损失\n",
    "        avg_train_loss = train_loss / len(train_dataset)\n",
    "    \n",
    "        # ---------------------- 验证阶段 ----------------------\n",
    "        net.eval()  # 切换验证模式（关闭Dropout/BatchNorm训练）\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():  # 关闭梯度计算，节省显存+加速\n",
    "            for batch_input, batch_target in val_dataloader:\n",
    "                batch_input, batch_target = batch_input.to(device), batch_target.to(device)\n",
    "                \n",
    "                #验证阶段只需要 前向传播 和 计算损失\n",
    "                output = net(batch_input)\n",
    "                loss = criterion(output, batch_target)\n",
    "                val_loss += loss.item() * batch_size\n",
    "    \n",
    "        # 计算本轮验证平均损失\n",
    "        avg_val_loss = val_loss / len(val_dataset)\n",
    "    \n",
    "        # ----------------------- 进度条 -----------------------\n",
    "        pbar.set_postfix({\n",
    "            \"Train Loss\": f\"平均训练损失{avg_train_loss:.4f}\",\n",
    "            \"Val Loss\": f\"平均验证损失{avg_val_loss:.4f}\"\n",
    "        })\n",
    "        \n",
    "print(\"batchsize=200:\")\n",
    "different_batch_zize_train(200)\n",
    "print(\"batchsize=100:\")\n",
    "different_batch_zize_train(100)\n",
    "print(\"batchsize=50:\")\n",
    "different_batch_zize_train(50)\n",
    "print(\"batchsize=10:\")\n",
    "different_batch_zize_train(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24fe437-d65a-4a62-a0d0-91656480a081",
   "metadata": {},
   "source": [
    "**可以看到不同batchsize的对结果的影响，有时间可以仿照写出不同lr对结果的影响**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b01e75b-9e8f-45aa-bae9-e6d63f48136b",
   "metadata": {},
   "source": [
    "## 占位符（未来再写）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bbf68f-fc85-41d6-9afc-127355de3b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
