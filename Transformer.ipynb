{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55a0207-3fde-4d5e-a982-ba8ab7f397e4",
   "metadata": {},
   "source": [
    "环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "d3f0160c-4664-471b-a135-8c297ad9ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "a6b6ba22-c430-4c4c-ad24-c7e2e1adbe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed=3407):                   #3407 is all you need!\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "c9c9e3e3-9035-40ec-ab70-b32befdfe408",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a9440d-94f5-4c2a-bd91-1e067c475368",
   "metadata": {},
   "source": [
    "## 最最简单Transformer运行尝试（玩一下先）\n",
    "使用pytorch官方的nn.Transformer() 和 HuggingFace transformers 库的位置编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "ceccf927-f38d-4c00-b540-25194b478a4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.46.3\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: d:\\anaconda3\\envs\\yolov8\\lib\\site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "# pip install transformers\n",
    "!pip show transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "6f6e65c8-0bbc-4288-8aa2-97052308c576",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.bert.modeling_bert import BertConfig, BertEmbeddings  # 现成BERT的嵌入层 + 位置编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "71646377-a19d-4f07-aff1-6c4cf5f8d17d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n",
      "tensor([[2, 8, 6, 9, 8, 1, 4, 4, 3, 1],\n",
      "        [5, 1, 6, 3, 8, 6, 7, 2, 6, 4],\n",
      "        [2, 4, 7, 2, 7, 7, 1, 3, 8, 9],\n",
      "        [6, 2, 7, 2, 8, 5, 8, 5, 3, 2],\n",
      "        [5, 7, 4, 3, 6, 5, 8, 7, 6, 1],\n",
      "        [7, 1, 3, 6, 7, 6, 3, 1, 9, 9],\n",
      "        [7, 9, 2, 3, 4, 3, 8, 2, 7, 3],\n",
      "        [3, 8, 6, 3, 3, 1, 9, 1, 8, 4]], device='cuda:0')\n",
      "tensor([[1, 3, 4, 4, 1, 8, 9, 6, 8, 2],\n",
      "        [4, 6, 2, 7, 6, 8, 3, 6, 1, 5],\n",
      "        [9, 8, 3, 1, 7, 7, 2, 7, 4, 2],\n",
      "        [2, 3, 5, 8, 5, 8, 2, 7, 2, 6],\n",
      "        [1, 6, 7, 8, 5, 6, 3, 4, 7, 5],\n",
      "        [9, 9, 1, 3, 6, 7, 6, 3, 1, 7],\n",
      "        [3, 7, 2, 8, 3, 4, 3, 2, 9, 7],\n",
      "        [4, 8, 1, 9, 1, 3, 3, 6, 8, 3]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# 核心配置: 设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device = {device}\")\n",
    "# 模型维度、多头自注意力的头数\n",
    "d_model, nhead= 64, 8\n",
    "# 序列长度、一个批次的大小\n",
    "sequence_length, batch_size = 10, 8\n",
    "# 训练轮数、学习率\n",
    "epochs, lr = 100, 0.001\n",
    "\n",
    "#------------------------------Transformer------------------------------------\n",
    "net = nn.Transformer(d_model=d_model, nhead=nhead, batch_first=True).to(device)\n",
    "\n",
    "#----------------------调用现成的BERT的嵌入层 + 位置编码）--------------------\n",
    "bert_config = BertConfig(\n",
    "    vocab_size=10,                            # 词表大小\n",
    "    hidden_size=d_model,                      # 对应d_model\n",
    "    max_position_embeddings=sequence_length,  # 最大序列长度\n",
    "    num_attention_heads=nhead,\n",
    ")\n",
    "bert_embeddings = BertEmbeddings(bert_config).to(device)\n",
    "#-----------------------------------------------------------------------------\n",
    "\n",
    "fc_out = nn.Linear(d_model, 10).to(device)\n",
    "#损失函数 和 优化器\n",
    "# criterion = nn.MSELoss()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(list(net.parameters()) + list(fc_out.parameters()), lr=lr)\n",
    "\n",
    "# 随机数据\n",
    "input = torch.randint(1, vocab_size, (batch_size, sequence_length)).to(device)  # 避免0（PAD）\n",
    "target = torch.flip(input, dims=[1]).to(device)  # target是input的逆序\n",
    "print(input, target, sep=\"\\n\")\n",
    "kokomi_input, kokomi_target = input, target #给全文最后一步对比的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "f22f086e-cbb3-4d82-ad39-bb962791343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度: 100%|██████████| 100/100 [00:05<00:00, 18.78it/s, Loss=2.0822]\n"
     ]
    }
   ],
   "source": [
    "net.train()\n",
    "pbar = tqdm(range(epochs), desc=\"训练进度\")\n",
    "\n",
    "for epoch in pbar:\n",
    "    #------------------位置编码--------------------------\n",
    "    input_embeddings = bert_embeddings(input_ids=input)\n",
    "    # Decoder输入用target[:, :-1]（右移一位，长度9），避免泄露未来token   (官方的需要)\n",
    "    target_ = target[:, :-1]\n",
    "    target_embeddings = bert_embeddings(input_ids=target_)\n",
    "    #---------------------------------------------------\n",
    "    \n",
    "    #--------------几乎通用的训练流程-----------------\n",
    "    optimizer.zero_grad()\n",
    "    out = net(input_embeddings, target_embeddings)     #解码器必须接收目标序列才能工作\n",
    "    out = fc_out(out)                                  #映射到vocab_size（和自定义模型的fc_out对齐）\n",
    "    loss = criterion(out.reshape(-1, 10), target[:, 1:].reshape(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "    #-----------------------------------------------\n",
    "    \n",
    "#没有装flash-attention，报错是正常的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b69281-e516-4b49-8c3d-829ce743665c",
   "metadata": {},
   "source": [
    "## 一、嵌入层和位置编码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0c7afb-511a-4d8f-9178-bcfd216529c7",
   "metadata": {},
   "source": [
    "### 嵌入层"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cee6c2-a884-44ab-bd9a-787f87405ce2",
   "metadata": {},
   "source": [
    "嵌入层的核心作用：  \n",
    "每个 元素 转成 可学习的 高维向量：比如 “我”->[0.1, 0.2, 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "fe151baf-4325-49a0-a62c-9df9852e9791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3, 5, 9, 9, 0, 0, 0, 1, 3, 9],\n",
       "         [5, 2, 0, 3, 0, 5, 3, 5, 8, 1],\n",
       "         [4, 2, 1, 0, 2, 7, 5, 2, 3, 4],\n",
       "         [4, 7, 4, 8, 0, 6, 2, 9, 4, 9]]),\n",
       " torch.Size([4, 10, 16]))"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_model = 16\n",
    "batch_size = 4\n",
    "sequence_length = 10\n",
    "x = torch.randint(0, 10, (batch_size, sequence_length))\n",
    "\n",
    "embedding = nn.Embedding(num_embeddings=10, embedding_dim=d_model)\n",
    "X = embedding(x)\n",
    "\n",
    "x, X.size() #16就是每个元素的向量特征维度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280982ab-4e13-40e1-babb-a59f19b20356",
   "metadata": {},
   "source": [
    "### 位置编码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dec5594-18ea-46fc-b7a1-01660c971819",
   "metadata": {},
   "source": [
    "Transformer原论文位置编码实现  \r\n",
    "\n",
    "PE(pos, 2i)   =  sin(pos / 10000^(2i/d_model))  \n",
    "PE(pos, 2i+1) =  cos(pos / 10000^(2i/d_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "8e77c6a0-628b-4170-b9e5-f524623be759",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    #需要参数 ：模型特征维度，丢弃率，最大序列长度（位置维度）（要保证每个元素编码不同，所以必须 >= 原始序列长度）\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 生成位置编码矩阵 [1, max_len, d_model]\n",
    "        self.P = torch.zeros(1, max_len, d_model)       #1：batch 维度的占位符（表示 “适配任意 batch 大小”）\n",
    "        # pos: 第几个 token\n",
    "        self.pos = torch.arange(0, max_len, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "        # i：每个 token 的第几个特征\n",
    "        #2i/d_model  step=2为偶数索引，对应了2i\n",
    "        self.two_i_divide_dmodel = torch.arange(0, d_model, step=2, dtype=torch.float32) / d_model\n",
    "        #10,000^(2i/d_model)\n",
    "        self.ten_thousands_pow_two_i_divide_dmodel = torch.pow(10000, self.two_i_divide_dmodel)\n",
    "        #pos / 10000^(2i/d_model)\n",
    "        self.X = self.pos / self.ten_thousands_pow_two_i_divide_dmodel\n",
    "        \n",
    "        #奇数特征位置计算cos，偶数特征位置计算sin\n",
    "        self.even_cos =torch.cos(self.X)\n",
    "        self.odd_sin = torch.sin(self.X)\n",
    "        \n",
    "        # 0::2 表示从0开始到最后一个位置，步长为2       1::2 表示从1开始到最后一个位置，步长为2\n",
    "        self.P[:, :, 0::2] = self.odd_sin\n",
    "        self.P[:, :, 1::2] = self.even_cos\n",
    "\n",
    "    def forward(self, x):\n",
    "        #位置编码，因为第二维max_len可能大于x的序列长度，因此要去掉多出的部分，并且放到x所在的设备上\n",
    "        p = self.P[:,:x.shape[1],:].to(x.device)\n",
    "        #输入 叠加 位置编码\n",
    "        x = x + p\n",
    "        #随机让一部分特征值变为 0，增加泛化能力，提高正则化效果\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "7aa356fd-dd6e-4032-bcf0-0c753820ea7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 16])\n",
      "torch.Size([4, 10, 16])\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "pos_encoding = PositionalEncoding(d_model=16, dropout=0.1, max_len=10)\n",
    "print(pos_encoding.P.size())\n",
    "\n",
    "X_emb = pos_encoding(X)\n",
    "print(X_emb.size())\n",
    "# 1 -> 4是因为python的广播机制，4个batch用的是相同的位置编码"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6e3782-1af5-460a-ad7a-ff1852e84596",
   "metadata": {},
   "source": [
    "## 二、多头自注意力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d9ce9d-a350-457b-a382-a4418cd31562",
   "metadata": {},
   "source": [
    "### 使用官方 自注意力和多头自注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "5178aaf4-85b6-4882-b4a2-9dc2e87ed5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 16]) torch.Size([4, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "self_attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=1, batch_first=True)\n",
    "attention_out, attention_weight = self_attention(\n",
    "    query=X_emb,    # 查询向量（当前token）\n",
    "    key=X_emb,      # 键向量（所有token）\n",
    "    value=X_emb     # 值向量（所有token）\n",
    ")\n",
    "#out = 每个 token 融合了序列中所有 token 信息后的最终特征向量\n",
    "#weight = 每个 token 对其他所有 token 的注意力分数（关注程度）\n",
    "print(attention_out.size(), attention_weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "19c01a5d-4a54-40e8-a4a9-9db0f4e593a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 16]) torch.Size([4, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "self_attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=4, batch_first=True)\n",
    "attention_out, attention_weight = self_attention(\n",
    "    query=X_emb,    \n",
    "    key=X_emb,     \n",
    "    value=X_emb  \n",
    ")\n",
    "print(attention_out.size(), attention_weight.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788f64af-3aa3-4479-a8d1-6ceddd940e3f",
   "metadata": {},
   "source": [
    "### 手动实现多头自注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "54c2f306-1b29-4a4b-8fcf-489eb69f4189",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, num_heads=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model               #模型特征维度\n",
    "        self.num_heads = num_heads           #多头数量\n",
    "        self.d_head = d_model // num_heads   #每个头的维度（必须整除）  单头时此项为 K的维度\n",
    "        \n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_out = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        #--------------发现loss基本不下降，于是试试初始化------------\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"对齐官方nn.MultiheadAttention的初始化逻辑：Xavier均匀分布\"\"\"\n",
    "        for m in [self.w_q, self.w_k, self.w_v, self.w_out]:\n",
    "            # Xavier初始化：适合线性层+tanh/ReLU激活\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            # 偏置初始化为0（官方默认）\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length, d_model = x.shape\n",
    "\n",
    "        # 步骤1：生成Q、K、V（线性变换）\n",
    "        Q = self.w_q(x)  # [batch, seq, d_model]\n",
    "        K = self.w_k(x)  # [batch, seq, d_model]\n",
    "        V = self.w_v(x)  # [batch, seq, d_model]\n",
    "\n",
    "        # 步骤2：拆分多头（num_heads=1时，这一步无变化）\n",
    "        # 维度变为：[batch, num_heads, seq_len, d_head]\n",
    "        Q = Q.view(batch_size, sequence_length, self.num_heads, self.d_head).transpose(1, 2)\n",
    "        K = K.view(batch_size, sequence_length, self.num_heads, self.d_head).transpose(1, 2)\n",
    "        V = V.view(batch_size, sequence_length, self.num_heads, self.d_head).transpose(1, 2)\n",
    "        \n",
    "        # 步骤3：计算注意力分数（Q×K^T / √d_head）\n",
    "        attention_scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.d_head, dtype=torch.float32))\n",
    "        \n",
    "        # 步骤4：Softmax归一化（得到注意力权重）\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)\n",
    "        \n",
    "        # 步骤5：注意力加权求和（权重×V）\n",
    "        attention_output = torch.matmul(attention_weights, V)\n",
    "        \n",
    "        # 步骤6：拼接多头\n",
    "        attention_output = attention_output.transpose(1, 2).contiguous().view(batch_size, sequence_length, self.d_model)\n",
    "        \n",
    "        #步骤7：输出线性变换\n",
    "        attention_output = self.w_out(attention_output)\n",
    "        \n",
    "        return attention_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21096925-b505-4155-bb1a-7abcc4e09b6a",
   "metadata": {},
   "source": [
    "测试手动实现的多头自注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "dceb435f-e17d-49d0-840c-666f1f502409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 16]) torch.Size([4, 2, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "self_attention = MultiHeadAttention(d_model=d_model, num_heads=2)\n",
    "attention_out, attention_weight = self_attention(X_emb)\n",
    "print(attention_out.size(), attention_weight.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d237742e-a527-4ab9-bd2b-f6bf3b074c00",
   "metadata": {},
   "source": [
    "### 使用 Einops 手动实现多头自注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "41ca211a-9825-4eec-805c-eca6495da761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from einops import rearrange, einsum\n",
    "\n",
    "class EinopsMultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_head = d_model // num_heads  \n",
    "\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, sequence_length, d_model = x.shape\n",
    "\n",
    "        #步骤 1不变\n",
    "        Q = self.w_q(x)  # [batch, seq, d_model]\n",
    "        K = self.w_k(x)  # [batch, seq, d_model]\n",
    "        V = self.w_v(x)  # [batch, seq, d_model]\n",
    "        \n",
    "        # ===================== 步骤 2：拆分多头（einops rearrange 替代 view+transpose） =====================\n",
    "        Q = rearrange(Q, 'b s (h d) -> b h s d', h=self.num_heads, d=self.d_head)  # [b, h, s, d]\n",
    "        K = rearrange(K, 'b s (h d) -> b h s d', h=self.num_heads, d=self.d_head)  # [b, h, s, d]\n",
    "        V = rearrange(V, 'b s (h d) -> b h s d', h=self.num_heads, d=self.d_head)  # [b, h, s, d]\n",
    "        \n",
    "        # ===================== 步骤 3：计算Q×K^T（einops einsum 替代 matmul+transpose） =====================\n",
    "        # 语法：einsum(张量1, 模式1, 张量2, 模式2, 输出模式)\n",
    "        # Q模式：b h s1 d → K模式：b h s2 d → 输出：b h s1 s2（s1=query_seq, s2=key_seq） 通过d相乘\n",
    "        attention_scores = einsum(Q, K, 'b h s1 d, b h s2 d -> b h s1 s2') / torch.sqrt(torch.tensor(self.d_head, dtype=torch.float32))\n",
    "\n",
    "        #步骤 4不变\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)  # [b, h, s1, s2]\n",
    "        \n",
    "        #步骤 5不变\n",
    "        attention_output = torch.matmul(attention_weights, V)\n",
    "        \n",
    "        # ===================== 步骤 6：拼接多头（einops rearrange 替代 transpose+view+contiguous） =====================\n",
    "        attention_output = rearrange(attention_output, 'b h s d -> b s (h d)')  # [b, s, d_model]\n",
    "        \n",
    "        #步骤 7不变\n",
    "        attention_output = self.w_out(attention_output)\n",
    "        \n",
    "        return attention_output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b143a38-1681-40e7-bca2-36af5ad99e48",
   "metadata": {},
   "source": [
    "测试使用 Einops 手动实现的多头自注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "b10bea7c-897f-47b5-845a-61cb4fa6908f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 10, 16]) torch.Size([4, 4, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "self_attention = EinopsMultiHeadAttention(d_model=d_model, num_heads=4)\n",
    "attention_out, attention_weight = self_attention(X_emb)\n",
    "print(attention_out.size(), attention_weight.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bb7aff-c087-4783-ba2e-f5b34b8eea07",
   "metadata": {},
   "source": [
    "## 三、编码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5801cbfe-311a-495b-bc38-784f6de891bf",
   "metadata": {},
   "source": [
    "### 使用官方nn.TransformerEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "14c6e7bd-b10d-4d81-be21-2cd34ee2662f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备：cuda\n",
      "x: tensor([[7, 1, 8, 5, 7, 8, 3, 7, 2, 2, 1, 2, 9, 5, 8, 0, 4, 4, 0, 4],\n",
      "        [6, 8, 1, 9, 4, 2, 2, 8, 3, 8, 6, 0, 4, 2, 3, 7, 6, 4, 6, 8],\n",
      "        [0, 8, 1, 1, 5, 3, 1, 8, 1, 8, 1, 1, 6, 2, 5, 7, 0, 7, 9, 9],\n",
      "        [8, 4, 1, 9, 1, 9, 9, 3, 3, 3, 3, 6, 6, 3, 5, 4, 4, 5, 0, 9]],\n",
      "       device='cuda:0')\n",
      "X_emb: torch.Size([4, 20, 16])\n",
      "\n",
      "============ 官方 TransformerEncoder 输出 ============\n",
      "编码器最终输出维度：torch.Size([4, 20, 16]) → 预期 [4, 20, 16]\n",
      "输出数据类型：torch.float32\n",
      "输出设备：cuda:0\n",
      "\n",
      "编码器总参数数：38496\n"
     ]
    }
   ],
   "source": [
    "d_model = 16\n",
    "num_heads = 4\n",
    "batch_size = 4\n",
    "ffn_dim = 256\n",
    "dropout = 0.1\n",
    "num_layers = 4\n",
    "sequence_length = 20\n",
    "max_len = sequence_length\n",
    "vocab_size = 10\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备：{device}\")\n",
    "\n",
    "encoder_layer = nn.TransformerEncoderLayer(\n",
    "    d_model=d_model,\n",
    "    nhead=num_heads,\n",
    "    dim_feedforward=ffn_dim,\n",
    "    dropout=dropout,\n",
    "    batch_first=True,  # 重点：设置batch在前，否则默认是[seq, batch, d_model]\n",
    "    activation=\"relu\",  # 激活函数（原论文用relu）\n",
    "    device=device\n",
    ")\n",
    "\n",
    "transformer_encoder = nn.TransformerEncoder(\n",
    "    encoder_layer=encoder_layer,\n",
    "    num_layers=num_layers,\n",
    "    norm=nn.LayerNorm(d_model).to(device)  # 最终层归一化（可选）\n",
    ")\n",
    "\n",
    "#随机生成输入\n",
    "x = torch.randint(0, vocab_size, (batch_size, sequence_length)).to(device)\n",
    "print(f\"x: {x}\")\n",
    "#输入嵌入\n",
    "embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=d_model).to(device)\n",
    "X = embedding(x)\n",
    "\n",
    "#使用我们的位置编码\n",
    "pos_encoding = PositionalEncoding(d_model=d_model, dropout=dropout, max_len=max_len).to(device)\n",
    "X_emb = pos_encoding(X)\n",
    "print(f\"X_emb: {X_emb.size()}\")\n",
    "\n",
    "#调用官方 TransformerEncoder\n",
    "encoder_out = transformer_encoder(X_emb, mask=None)\n",
    "\n",
    "# ===================== 打印结果验证 =====================\n",
    "print(\"\\n============ 官方 TransformerEncoder 输出 ============\")\n",
    "print(f\"编码器最终输出维度：{encoder_out.shape} → 预期 [4, 20, 16]\")\n",
    "print(f\"输出数据类型：{encoder_out.dtype}\")\n",
    "print(f\"输出设备：{encoder_out.device}\")\n",
    "\n",
    "# 可选：查看编码器的参数数量（验证参数被正确初始化）\n",
    "total_params = sum(p.numel() for p in transformer_encoder.parameters())\n",
    "print(f\"\\n编码器总参数数：{total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3407d8f2-b2a2-4d75-a8ba-a6f342865cf4",
   "metadata": {},
   "source": [
    "### 单层编码器手动版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "d3b5ea88-a695-42f9-9c63-7dfbfb9be7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    #参数： 模型特征维度、多头数、前馈网络特征维度、丢弃率\n",
    "    def __init__(self, d_model, num_heads, ffn_dim=1024, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 多头自注意力：使用第二章的代码\n",
    "        self.self_attn = MultiHeadAttention(d_model=d_model, num_heads=num_heads)\n",
    "        \n",
    "        # 前馈网络（FFN：Linear → ReLU → Dropout → Linear）\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ffn_dim),  # 升维（原论文ff_dim=4*d_model）\n",
    "            nn.ReLU(),                    # 激活\n",
    "            nn.Dropout(dropout),          # 丢弃一些，正则化效果提升\n",
    "            nn.Linear(ffn_dim, d_model)   # 降维回d_model\n",
    "        )\n",
    "        \n",
    "        # 层归一化（Pre-LN模式：先归一化，再做注意力/FFN）\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Dropout（残差连接后）\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 第一步：层归一化 + 多头自注意力 + 残差连接\n",
    "        x_norm = self.norm1(x)\n",
    "        attn_out, attn_weights = self.self_attn(x_norm)\n",
    "        # 残差连接：输入 x + 注意力输出（加dropout）\n",
    "        x = x + self.dropout1(attn_out)\n",
    "\n",
    "        # 第二步：层归一化 + 前馈网络 + 残差连接\n",
    "        x_norm = self.norm2(x)\n",
    "        ffn_out = self.ffn(x_norm)\n",
    "        # 残差连接：当前 x + FFN输出（加dropout）\n",
    "        x = x + self.dropout2(ffn_out)\n",
    "\n",
    "        return x, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d0e60a-834d-4cef-8f3a-598a902d644b",
   "metadata": {},
   "source": [
    "### 完整编码器手动版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "4099ee66-94d7-41c6-918b-37fc042a13dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    #参数：模型特征维度、多头数、词表大小（语言模型用）、层数、前馈网络特征维度、丢弃率、最大序列长度（建议=序列长度）\n",
    "    def __init__(self, d_model, num_heads, vocab_size, num_layers, ffn_dim=2048, dropout=0.1, max_len=1000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        # 1. 嵌入层（token → d_model维向量）\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        # 2. 位置编码（添加位置信息） 用的第一章实现的位置编码器\n",
    "        self.pos_encoding = PositionalEncoding(d_model=d_model, dropout=dropout, max_len=max_len)\n",
    "        \n",
    "        # 3. 多层编码器层（堆叠num_layers层）\n",
    "        layer_list = []\n",
    "        for _ in range(num_layers):\n",
    "            layer = EncoderLayer(d_model=d_model, num_heads=num_heads, ffn_dim=ffn_dim, dropout=dropout)\n",
    "            layer_list.append(layer)\n",
    "        self.layers = nn.ModuleList(layer_list)\n",
    "        #也可以用列表推导式，如下所示：\n",
    "        # self.layers = nn.ModuleList([\n",
    "        #     EncoderLayer(d_model=d_model, num_heads=num_heads, ffn_dim=ffn_dim, dropout=dropout)\n",
    "        #     for _ in range(num_layers)\n",
    "        # ])\n",
    "        \n",
    "        # 4. 最终层归一化（可选，提升稳定性）\n",
    "        self.final_norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "        #--------------发现loss基本不下降，于是试试初始化------------\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"初始化嵌入层+层归一化（可选）\"\"\"\n",
    "        # 嵌入层：Xavier初始化（和注意力层一致）\n",
    "        nn.init.xavier_uniform_(self.embedding.weight)\n",
    "        # 层归一化默认初始化已足够，无需额外操作\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 步骤1：嵌入层 + 缩放（原论文：embedding输出 × √d_model，平衡位置编码幅度）\n",
    "        x = self.embedding(x) * torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        \n",
    "        # 步骤2：添加位置编码\n",
    "        x = self.pos_encoding(x)\n",
    "        \n",
    "        # 步骤3：堆叠编码器层\n",
    "        all_attention_weights = []\n",
    "        for layer in self.layers:\n",
    "            x, attention_weights = layer(x)\n",
    "            all_attention_weights.append(attention_weights)\n",
    "            \n",
    "        # 步骤4：最终层归一化\n",
    "        encoder_out = self.final_norm(x)\n",
    "        \n",
    "        return encoder_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264c9da1-cd71-4d0e-957b-a2aa19f091fc",
   "metadata": {},
   "source": [
    "### 测试手动实现的编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "2e7dd747-3e9e-4bb4-840b-a70d10508617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 4, 2, 5, 7, 7, 1, 9, 2, 1],\n",
      "        [5, 6, 4, 6, 8, 1, 8, 9, 4, 5],\n",
      "        [3, 0, 7, 2, 7, 2, 0, 7, 9, 5],\n",
      "        [6, 7, 9, 5, 8, 4, 3, 3, 3, 4]])\n",
      "编码器最终输出维度：torch.Size([4, 10, 16]) → 预期 [4, 10, 16]\n",
      "输出数据类型：torch.float32\n",
      "输出设备：cpu\n",
      "\n",
      "编码器总参数数：38656\n"
     ]
    }
   ],
   "source": [
    "d_model = 16\n",
    "batch_size = 4\n",
    "sequence_length = 10\n",
    "\n",
    "encoder = Encoder(\n",
    "    vocab_size = 10,\n",
    "    d_model = d_model,\n",
    "    num_heads = 4,\n",
    "    num_layers = 4,\n",
    "    ffn_dim = 256,\n",
    "    dropout = 0.1,\n",
    "    max_len = sequence_length\n",
    ")\n",
    "\n",
    "x = torch.randint(0, 10, (batch_size, sequence_length))\n",
    "print(x)\n",
    "\n",
    "encoder_out = encoder(x)\n",
    "\n",
    "print(f\"编码器最终输出维度：{encoder_out.shape} → 预期 [4, 10, 16]\")\n",
    "print(f\"输出数据类型：{encoder_out.dtype}\")\n",
    "print(f\"输出设备：{encoder_out.device}\")\n",
    "\n",
    "# 可选：查看编码器的参数数量（验证参数被正确初始化）\n",
    "total_params = sum(p.numel() for p in encoder.parameters())\n",
    "print(f\"\\n编码器总参数数：{total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f846801e-663b-4d35-92c4-b74f03600f72",
   "metadata": {},
   "source": [
    "## 四、解码器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6bb51d-6f25-476b-a1ec-947c5c1aa8bf",
   "metadata": {},
   "source": [
    "### 使用官方nn.TransformerDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "306a096d-8a99-4770-8873-9555d2109b01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "编码器输出（memory）维度：torch.Size([4, 20, 16]) → [batch, src_seq, d_model]\n"
     ]
    }
   ],
   "source": [
    "# 解码器专属参数\n",
    "target_seq_length = 18  # 解码器目标序列长度（通常比编码器短/等长，测试用18）\n",
    "\n",
    "decoder_layer = nn.TransformerDecoderLayer(\n",
    "    d_model=d_model,\n",
    "    nhead=num_heads,\n",
    "    dim_feedforward=ffn_dim,\n",
    "    dropout=dropout,\n",
    "    batch_first=True,  # 输入维度 [batch, seq, d_model]\n",
    "    activation=\"relu\",\n",
    "    device=device\n",
    ")\n",
    "\n",
    "transformer_decoder = nn.TransformerDecoder(\n",
    "    decoder_layer=decoder_layer,\n",
    "    num_layers=num_layers,\n",
    "    norm=nn.LayerNorm(d_model).to(device)  # 最终层归一化\n",
    ")\n",
    "\n",
    "memory = transformer_encoder(X_emb, mask=None)\n",
    "print(f\"编码器输出（memory）维度：{memory.shape} → [batch, src_seq, d_model]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "fdd7c340-606c-4a3c-b0ac-43a5c4856499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "解码器目标输入（target_x）维度：torch.Size([4, 18])\n",
      "解码器嵌入+位置编码后维度：torch.Size([4, 18, 16])\n",
      "\n",
      "未来掩码（target_mask）维度：torch.Size([18, 18])\n",
      "\n",
      "============ 官方 TransformerDecoder 输出 =============\n",
      "解码器最终输出维度：torch.Size([4, 18, 16]) → 预期 [4, 18, 16]\n",
      "输出数据类型：torch.float32\n",
      "输出设备：cuda:0\n",
      "\n",
      "编码器总参数数：38496\n",
      "解码器总参数数：42976\n",
      "编码器+解码器总参数数：81472\n"
     ]
    }
   ],
   "source": [
    "# 生成解码器目标输入（tgt_x）\n",
    "target_x = torch.randint(0, vocab_size, (batch_size, target_seq_length)).to(device)\n",
    "print(f\"\\n解码器目标输入（target_x）维度：{target_x.shape}\")\n",
    "\n",
    "# 解码器输入处理（嵌入+位置编码）\n",
    "target_embedding = nn.Embedding(num_embeddings=num_embeddings, embedding_dim=d_model).to(device)\n",
    "target_X = target_embedding(target_x)\n",
    "\n",
    "target_pos_encoding = PositionalEncoding(d_model=d_model, dropout=dropout, max_len=max_len).to(device)\n",
    "target_X_emb = target_pos_encoding(target_X)\n",
    "\n",
    "print(f\"解码器嵌入+位置编码后维度：{target_X_emb.shape}\")\n",
    "\n",
    "# 生成解码器关键掩码（核心！）\n",
    "# 掩码1：未来掩码（look-ahead mask）→ 防止解码器看到当前token之后的内容\n",
    "def generate_square_subsequent_mask(target_seq_length, device=device):\n",
    "    # 生成全 1矩阵\n",
    "    all_1 = torch.ones((target_seq_length, target_seq_length), device=device)\n",
    "    # 将全 1矩阵 转换为 上三角全 1矩阵\n",
    "    upper_triangle = torch.triu(all_1)\n",
    "    # 将上三角全 1矩阵 转换成 上三角布尔值矩阵 然后 行列互换 变成 下三角布尔值矩阵\n",
    "    mask = (upper_triangle == 1).transpose(0, 1)\n",
    "    # 转float格式\n",
    "    mask = mask.float()\n",
    "    # 0的位置填充成-inf    1的位置填充成0   得到注意力掩码\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf'))\n",
    "    mask = mask.masked_fill(mask == 1, float(0.0))\n",
    "    return mask\n",
    "\n",
    "target_mask = generate_square_subsequent_mask(target_seq_length, device)\n",
    "print(f\"\\n未来掩码（target_mask）维度：{target_mask.shape}\")\n",
    "\n",
    "# 掩码2：memory掩码（编码器输出掩码）→ 测试时设为None（无掩码）\n",
    "memory_mask = None\n",
    "\n",
    "decoder_out = transformer_decoder(tgt=target_X_emb, memory=memory, tgt_mask=target_mask, memory_mask=memory_mask)\n",
    "\n",
    "# ===================== 7. 验证输出 =====================\n",
    "print(\"\\n============ 官方 TransformerDecoder 输出 =============\")\n",
    "print(f\"解码器最终输出维度：{decoder_out.shape} → 预期 [4, 18, 16]\")\n",
    "print(f\"输出数据类型：{decoder_out.dtype}\")\n",
    "print(f\"输出设备：{decoder_out.device}\")\n",
    "# 查看编码器的参数数量\n",
    "total_params = sum(p.numel() for p in transformer_encoder.parameters())\n",
    "print(f\"\\n编码器总参数数：{total_params}\")\n",
    "# 查看解码器参数数量\n",
    "total_decoder_params = sum(p.numel() for p in transformer_decoder.parameters())\n",
    "print(f\"解码器总参数数：{total_decoder_params}\")\n",
    "print(f\"编码器+解码器总参数数：{total_decoder_params + sum(p.numel() for p in transformer_encoder.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c560f7df-f619-4acf-9225-0b6fba4f8ab4",
   "metadata": {},
   "source": [
    "### 单层解码器手动版"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36172ad6-f827-4a57-a6a0-781b2297e97b",
   "metadata": {},
   "source": [
    "注意力掩码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "bf2f8572-176c-4f76-a46e-0392f0258fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., -inf, -inf],\n",
       "         [0., 0., -inf],\n",
       "         [0., 0., 0.]]], device='cuda:0')"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#注意力掩码 / Look-Ahead Mask（前瞻掩码）/ Future Mask（未来掩码）\n",
    "def generate_square_subsequent_mask(target_seq_length, device=device):\n",
    "    # 生成全 1矩阵\n",
    "    all_1 = torch.ones((target_seq_length, target_seq_length), device=device)\n",
    "    # 将全 1矩阵 转换为 上三角全 1矩阵\n",
    "    upper_triangle = torch.triu(all_1)\n",
    "    # 将上三角全 1矩阵 转换成 上三角布尔值矩阵 然后 行列互换 变成 下三角布尔值矩阵\n",
    "    mask = (upper_triangle == 1).transpose(0, 1)\n",
    "    # 转float格式\n",
    "    mask = mask.float()\n",
    "    # 0的位置填充成-inf    1的位置填充成0   得到注意力掩码\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf'))\n",
    "    mask = mask.masked_fill(mask == 1, float(0.0))\n",
    "    return mask.unsqueeze(0) #扩展到(1, target_seq_length, target_seq_length)   适配batchsize\n",
    "    \n",
    "generate_square_subsequent_mask(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bea54e-2c2e-4866-ad10-ede7ad14dda7",
   "metadata": {},
   "source": [
    "记忆掩码（测试时设置None即可）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "468c412f-52e0-4b8f-9ed3-0347fd91ae1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 18, 20])\n"
     ]
    }
   ],
   "source": [
    "#实际业务中，不是所有样本的源序列都能填满 20 个 token（比如有的样本只有 15 个有效 token，剩下 5 个是 <PAD> 填充\n",
    "#解码器的交叉注意力层需要 “关注编码器的有效 token，忽略 <PAD>”—— 这就是 generate_input_target_mask 的核心价值\n",
    "\n",
    "#Memory Mask（记忆掩码）/ Source-Target Padding Mask（源 - 目标填充掩码）/ Encoder Output Mask（编码器输出掩码）\n",
    "def generate_input_target_mask(input_padding_mask, target_seq_length, device=device):\n",
    "    batch_size, input_seq_length = input_padding_mask.shape\n",
    "    # # 1. padding掩码：False→PAD位置，True→有效位置\n",
    "    padding_mask = input_padding_mask\n",
    "    # 2. 扩展维度：[batch, 1, target_seq, src_seq] → 适配交叉注意力的维度 [batch, num_heads, target_seq, src_seq]\n",
    "    mask = padding_mask.unsqueeze(1).expand(-1, target_seq_length, -1)\n",
    "    # 3. 填充-inf（让softmax后权重为0），0（有效位置）\n",
    "    mask = mask.float()\n",
    "    mask = mask.masked_fill(mask == 0, float('-inf'))\n",
    "    mask = mask.masked_fill(mask == 1, 0.0)\n",
    "    return mask.to(device)\n",
    "\n",
    "#源序列padding掩码：[batch, seq_len] = [4,20]\n",
    "input_padding_mask = torch.tensor([\n",
    "    [True,True,True,True,True,True,True,True,True,True,False,False,False,False,False,False,False,False,False,False],  \n",
    "    [True,True,True,True,True,True,True,True,False,False,False,False,False,False,False,False,False,False,False,False],  \n",
    "    [True,True,True,True,True,True,True,True,True,True,True,True,True,True,True,True,False,False,False,False], \n",
    "    [True,True,True,True,True,True,True,True,True,True,True,True,True,True,True,True,True,True,True,True], \n",
    "]).to(device)\n",
    "\n",
    "input_target_mask = generate_input_target_mask(input_padding_mask, target_seq_length=18, device=device)\n",
    "print(input_target_mask.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28736b05-dfd9-44eb-afd8-13e54d0494c1",
   "metadata": {},
   "source": [
    "多头掩码自注意力（对多头注意力修改了两个地方）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "64f8ba82-723e-4338-9700-c61133a70605",
   "metadata": {},
   "outputs": [],
   "source": [
    "#多头掩码注意力（两处修改）\n",
    "class EinopsMultiHeadMaskAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_head = d_model // num_heads  \n",
    "\n",
    "        self.w_q = nn.Linear(d_model, d_model)\n",
    "        self.w_k = nn.Linear(d_model, d_model)\n",
    "        self.w_v = nn.Linear(d_model, d_model)\n",
    "        self.w_out = nn.Linear(d_model, d_model)\n",
    "\n",
    "        #--------------发现loss基本不下降，于是试试初始化------------\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"Xavier初始化：适配线性层+注意力的数值分布\"\"\"\n",
    "        for m in [self.w_q, self.w_k, self.w_v, self.w_out]:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):  # 改动1：输入改为q/k/v，增加mask参数              \n",
    "        # -------------兼容q/k/v序列长度不同的场景（如交叉注意力：q=tgt_seq, k/v=src_seq）------------------\n",
    "        batch_size =q.shape[0] \n",
    "        seq_len_q = q.shape[1]\n",
    "        seq_len_k = k.shape[1]\n",
    "        # 步骤 1：线性变换生成Q/K/V（逻辑不变，输入从x改为q/k/v）\n",
    "        Q = self.w_q(q)  # [batch, seq_q, d_model]\n",
    "        K = self.w_k(k)  # [batch, seq_k, d_model]\n",
    "        V = self.w_v(v)  # [batch, seq_k, d_model]\n",
    "        # ----------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # 步骤 2：拆分多头（einops rearrange 替代 view+transpose，逻辑不变）\n",
    "        Q = rearrange(Q, 'b s (h d) -> b h s d', h=self.num_heads, d=self.d_head)  # [b, h, seq_q, d_head]\n",
    "        K = rearrange(K, 'b s (h d) -> b h s d', h=self.num_heads, d=self.d_head)  # [b, h, seq_k, d_head]\n",
    "        V = rearrange(V, 'b s (h d) -> b h s d', h=self.num_heads, d=self.d_head)  # [b, h, seq_k, d_head]\n",
    "        \n",
    "        # 步骤 3：计算Q×K^T（einops einsum，适配seq_q/seq_k不同长度）不变\n",
    "        # 注意：输出维度变为 [b, h, seq_q, seq_k]（兼容交叉注意力）\n",
    "        attention_scores = einsum(Q, K, 'b h s1 d, b h s2 d -> b h s1 s2') \n",
    "        # 优化：指定device避免CPU/GPU不匹配，同时除以√d_head\n",
    "        attention_scores = attention_scores / torch.sqrt(torch.tensor(self.d_head, dtype=torch.float32, device=Q.device))\n",
    "\n",
    "        # --------------------------步骤 4：新增——应用掩码（解码器核心需求）------------------------------\n",
    "        if mask is not None:\n",
    "            # mask维度要求：[batch, 1, seq_q, seq_k] 或 [batch, num_heads, seq_q, seq_k]（einops自动广播）\n",
    "            attention_scores = attention_scores + mask\n",
    "        # ---------------------------------------------------------------------------------------------\n",
    "        \n",
    "        # 步骤 5：Softmax归一化（逻辑不变）\n",
    "        attention_weights = F.softmax(attention_scores, dim=-1)  # [b, h, seq_q, seq_k]\n",
    "        \n",
    "        # 步骤 6：注意力加权求和（逻辑不变）\n",
    "        attention_output = torch.matmul(attention_weights, V)  # [b, h, seq_q, d_head]\n",
    "        \n",
    "        # 步骤 7：拼接多头（einops rearrange，逻辑不变）\n",
    "        attention_output = rearrange(attention_output, 'b h s d -> b s (h d)')  # [b, seq_q, d_model]\n",
    "        \n",
    "        # 步骤 8：输出线性变换（逻辑不变）\n",
    "        attention_output = self.w_out(attention_output)\n",
    "        \n",
    "        return attention_output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "91c9adca-178f-4494-ad19-6459bbdf8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ffn_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        # 1. 掩码多头自注意力（屏蔽未来位置）\n",
    "        self.self_attn = EinopsMultiHeadMaskAttention(d_model, num_heads)\n",
    "        # 2. 编码器-解码器注意力（关注编码器输出）\n",
    "        self.cross_attn = EinopsMultiHeadMaskAttention(d_model, num_heads)\n",
    "        # 3. 前馈网络\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ffn_dim),  # 升维（原论文ff_dim=4*d_model）\n",
    "            nn.ReLU(),                    # 激活\n",
    "            nn.Dropout(dropout),          # 丢弃一些，正则化效果提升\n",
    "            nn.Linear(ffn_dim, d_model)   # 降维回d_model\n",
    "        )\n",
    "        \n",
    "        # 层归一化（每层注意力/前馈后都要做）\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Dropout（可选，增强鲁棒性）\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, target, encoder_out, target_mask=None, input_target_mask=None):\n",
    "        \n",
    "        #第一步：层归一化 + 多头掩码自注意力 + 残差连接   层归一化也可以在最后\n",
    "        target_norm = self.norm1(target)\n",
    "        mask_attention_out, mask_attention_weights = self.self_attn(target_norm, target_norm, target_norm, mask=target_mask)\n",
    "        # 残差连接：输入 x + 注意力输出（加dropout）\n",
    "        target = target + self.dropout1(mask_attention_out)\n",
    "\n",
    "        ## 第二步：层归一化 + 多头交叉掩码自注意力 + 残差连接   层归一化也可以在最后\n",
    "        target_norm = self.norm2(target)\n",
    "        # K和 V改成编码器输出的\n",
    "        cross_attention_out, cross_attention_weights = self.cross_attn(target_norm, encoder_out, encoder_out, mask=input_target_mask)\n",
    "        # 残差连接：输入 x + 注意力输出（加dropout）\n",
    "        target = target + self.dropout2(cross_attention_out)\n",
    "\n",
    "        # 第三步：层归一化 + 前馈网络 + 残差连接\n",
    "        target_norm = self.norm3(target)\n",
    "        ffn_out = self.ffn(target_norm)\n",
    "        # 残差连接：当前 x + FFN输出（加dropout）\n",
    "        target = target + self.dropout3(ffn_out)\n",
    "\n",
    "        return target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603679a5-f074-4499-9748-1d423b571233",
   "metadata": {},
   "source": [
    "### 完整解码器手动版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "c2e61158-13ef-43b9-893c-b8167d962779",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    #参数不再介绍了，同编码器\n",
    "    def __init__(self, d_model, num_heads, vocab_size, num_layers, ffn_dim=2048, dropout=0.1, max_len=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        self.d_model = d_model\n",
    "        # 1. 目标序列词嵌入层（token → d_model维向量）\n",
    "        self.target_embedding = nn.Embedding(vocab_size, d_model)\n",
    "        # 2. 位置编码（添加位置信息） 用的第一章实现的位置编码器\n",
    "        self.pos_encoding = PositionalEncoding(d_model=d_model, dropout=dropout, max_len=max_len)\n",
    "        \n",
    "        # 3. 多层解码器层（堆叠num_layers层）\n",
    "        layer_list = []\n",
    "        for _ in range(num_layers):\n",
    "            layer = DecoderLayer(d_model=d_model, num_heads=num_heads, ffn_dim=ffn_dim, dropout=dropout)\n",
    "            layer_list.append(layer)\n",
    "        self.layers = nn.ModuleList(layer_list)\n",
    "        #也可以用列表推导式，如下所示：\n",
    "        # self.layers = nn.ModuleList([\n",
    "        #     DecoderLayer(d_model, n_heads, ffn_dim, dropout)\n",
    "        #     for _ in range(num_layers)\n",
    "        # ])\n",
    "        \n",
    "        # 4. 最终线性层（将d_model映射到词表大小，用于预测token）\n",
    "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "        # 5. Dropout（可选，增强鲁棒性）\n",
    "        self.dropout = nn.Dropout(dropout)  \n",
    "        \n",
    "        #--------------发现loss基本不下降，于是试试初始化------------\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        \"\"\"初始化嵌入层和最终预测层\"\"\"\n",
    "        # 嵌入层初始化\n",
    "        nn.init.xavier_uniform_(self.target_embedding.weight)\n",
    "        # 最终预测层初始化\n",
    "        nn.init.xavier_uniform_(self.fc_out.weight)\n",
    "        if self.fc_out.bias is not None:\n",
    "            nn.init.zeros_(self.fc_out.bias)\n",
    "        \n",
    "    def forward(self, target, encoder_out, target_mask=None, input_target_mask=None):\n",
    "        batch_size, seq_len = target.shape\n",
    "        \n",
    "        # 步骤1：词嵌入 + 缩放（论文要求：embedding输出 × √d_model，平衡位置编码量级）\n",
    "        target = self.target_embedding(target) * torch.sqrt(torch.tensor(self.d_model, dtype=torch.float32))\n",
    "        \n",
    "        # 步骤2：叠加位置编码\n",
    "        target = self.pos_encoding(target) \n",
    "        \n",
    "        # 步骤3：逐层通过解码器层\n",
    "        for layer in self.layers:\n",
    "            target = layer(target, encoder_out, target_mask, input_target_mask)\n",
    "        \n",
    "        # 步骤4：最终线性层（映射到词表大小，用于预测下一个token）\n",
    "        # 【注意】不做softmax：训练时CrossEntropyLoss内部包含softmax，避免重复计算\n",
    "        decoder_output = target\n",
    "        fc_output = self.fc_out(target)\n",
    "        \n",
    "        return decoder_output, fc_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc30816c-491a-4e10-b75b-3a5f3f568785",
   "metadata": {},
   "source": [
    "### 测试手动实现的解码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "844ef48d-fee2-44db-aa90-64699e614cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "解码器目标输入（target_x）维度：torch.Size([4, 18])\n",
      "\n",
      "未来掩码（target_mask）维度：torch.Size([1, 18, 18])\n",
      "\n",
      "============ 我们的 TransformerDecoder 输出 =============\n",
      "解码器输出维度：torch.Size([4, 18, 16]) → 预期 [4, 18, 16]\n",
      "输出数据类型：torch.float32\n",
      "输出设备：cuda:0\n",
      "特征映射到词表后的最终输出维度：torch.Size([4, 18, 10]) → 预期 [4, 18, 10]\n",
      "\n",
      "编码器总参数数：38496\n",
      "解码器总参数数：42976\n",
      "编码器+解码器总参数数：81472\n"
     ]
    }
   ],
   "source": [
    "target_x = torch.randint(0, vocab_size, (batch_size, target_seq_length)).to(device)\n",
    "print(f\"\\n解码器目标输入（target_x）维度：{target_x.shape}\")\n",
    "\n",
    "# 掩码1：未来掩码（look-ahead mask）→ 防止解码器看到当前token之后的内容\n",
    "target_mask = generate_square_subsequent_mask(target_seq_length, device)\n",
    "print(f\"\\n未来掩码（target_mask）维度：{target_mask.shape}\")\n",
    "\n",
    "# 掩码2：memory掩码（编码器输出掩码）→ 测试时设为None（无掩码）\n",
    "memory_mask = None\n",
    "\n",
    "\n",
    "decoder = Decoder(\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    ffn_dim=ffn_dim,\n",
    "    num_layers=num_layers,\n",
    "    vocab_size=vocab_size,\n",
    "    dropout=0.1,\n",
    "    max_len=target_seq_length\n",
    ").to(device)\n",
    "decoder_out, fc_out = decoder(target=target_x, encoder_out=memory, target_mask=target_mask, input_target_mask=memory_mask)\n",
    "\n",
    "# ===================== 7. 验证输出 =====================\n",
    "print(\"\\n============ 我们的 TransformerDecoder 输出 =============\")\n",
    "print(f\"解码器输出维度：{decoder_out.shape} → 预期 [4, 18, 16]\")\n",
    "print(f\"输出数据类型：{decoder_out.dtype}\")\n",
    "print(f\"输出设备：{decoder_out.device}\")\n",
    "print(f\"特征映射到词表后的最终输出维度：{fc_out.shape} → 预期 [4, 18, 10]\")\n",
    "# 查看编码器的参数数量\n",
    "total_params = sum(p.numel() for p in transformer_encoder.parameters())\n",
    "print(f\"\\n编码器总参数数：{total_params}\")\n",
    "# 查看解码器参数数量\n",
    "total_decoder_params = sum(p.numel() for p in transformer_decoder.parameters())\n",
    "print(f\"解码器总参数数：{total_decoder_params}\")\n",
    "print(f\"编码器+解码器总参数数：{total_decoder_params + sum(p.numel() for p in transformer_encoder.parameters())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a78de8-80bd-43fc-ab26-251629ae92d0",
   "metadata": {},
   "source": [
    "## 五、Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a57b9-697d-478a-8af3-dd3406e05749",
   "metadata": {},
   "source": [
    "### Transformer手动实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670bb669-18f8-441d-94ee-c1d131a11db8",
   "metadata": {},
   "source": [
    "回顾一下之前的模块名   \n",
    "\n",
    "嵌入层：nn.Embedding   \n",
    "位置编码：PositionalEncoding   \n",
    "\n",
    "Einops实现的多头自注意力：EinopsMultiHeadAttention   \n",
    "编码器层：EncoderLayer   \n",
    "编码器：Encoder  \n",
    "\n",
    "注意力掩码：generate_square_subsequent_mask  \n",
    "记忆掩码：generate_input_target_mask  \n",
    "多头掩码自注意力：EinopsMultiHeadMaskAttention  \n",
    "解码器层：DecoderLayer  \n",
    "解码器：Decoder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "86acd140-fafc-4bcb-9d81-5a292b88000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    #参数不解释了\n",
    "    def __init__(self, d_model, num_heads, ffn_dim, num_layers, vocab_size, max_len, dropout=0.1):\n",
    "        super().__init__()\n",
    "        #编码器\n",
    "        self.encoder = Encoder(\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            ffn_dim=ffn_dim,\n",
    "            num_layers=num_layers,\n",
    "            vocab_size=vocab_size,\n",
    "            max_len=max_len,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        #解码器\n",
    "        self.decoder = Decoder(\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            ffn_dim=ffn_dim,\n",
    "            num_layers=num_layers,\n",
    "            vocab_size=vocab_size,\n",
    "            max_len=max_len,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "    def forward(self, x, target, target_mask=None, input_target_mask=None):\n",
    "        # 1. 先编码 # [batch, src_seq_len, d_model]\n",
    "        encoder_out = self.encoder(x) \n",
    "        # 2. 后解码 # [batch, target_seq_len, vocab_size]\n",
    "        decoder_out, fc_out = self.decoder(target, encoder_out, target_mask, input_target_mask)  \n",
    "        return decoder_out, fc_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c197eb-48f9-488b-a8b6-db724762301b",
   "metadata": {},
   "source": [
    "### 测试手动实现的Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "d7d6f964-3c41-485d-878f-ff9be44fca89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "编码器输入（x）维度：torch.Size([4, 20]) → [4,20]\n",
      "解码器输入（target）维度：torch.Size([4, 18]) → [4,18]\n",
      "编码器PAD掩码维度：torch.Size([4, 20]) → [4,20]\n",
      "注意力掩码（target_mask）维度：torch.Size([1, 18, 18]) → [18,18]\n",
      "记忆掩码（input_target_mask）维度：torch.Size([4, 18, 20]) → [4,18,20]\n",
      "Transformer输出维度：torch.Size([4, 18, 16]) → 预期[4,18,16]\n",
      "特征映射到词表后的最终输出维度：torch.Size([4, 18, 10]) → 预期 [4, 18, 10]\n",
      "==================================================\n",
      "模型设备：cuda:0\n",
      "输出设备：cuda:0\n",
      "\n",
      "总参数数：81930\n"
     ]
    }
   ],
   "source": [
    "# 0.设置参数\n",
    "d_model = 16                  #模型特征维度\n",
    "num_heads = 4                 #多头数\n",
    "batch_size = 4                #一个批次的大小\n",
    "ffn_dim = 256                 #前馈网络特征维度\n",
    "dropout = 0.1                 #丢弃率\n",
    "num_layers = 4                #编码器和解码器的层数\n",
    "sequence_length = 20          #序列长度\n",
    "max_len = sequence_length     #最大序列长度，最好=序列长度\n",
    "vocab_size = 10               #词表大小（语言类用）\n",
    "target_seq_length = 18        #目标序列长度\n",
    "\n",
    "# 1. 初始化完整Transformer\n",
    "transformer = Transformer(\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    ffn_dim=ffn_dim,\n",
    "    num_layers=num_layers,\n",
    "    vocab_size=vocab_size,\n",
    "    max_len=max_len,\n",
    "    dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "# 2. 生成测试输入\n",
    "# 编码器输入（src）：[batch, seq_len]\n",
    "x = torch.randint(0, vocab_size, (batch_size, sequence_length)).to(device)\n",
    "# 解码器输入（target）：[batch, target_seq_len]\n",
    "target = torch.randint(0, vocab_size, (batch_size, target_seq_length)).to(device)\n",
    "# 模拟编码器PAD掩码 1：有效，  0：<PAD>\n",
    "input_padding_mask = torch.tensor([\n",
    "    [1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0],\n",
    "    [1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "    [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0],\n",
    "    [1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1],\n",
    "]).to(device)\n",
    "\n",
    "# 3. 生成掩码\n",
    "target_mask = generate_square_subsequent_mask(target_seq_length, device)  # [18,18]\n",
    "input_target_mask = generate_input_target_mask(input_padding_mask, target_seq_length, device)  # [4,18,20]\n",
    "\n",
    "# 4. 前向传播\n",
    "output, fc_out = transformer(x, target, target_mask, input_target_mask)\n",
    "\n",
    "# 5. 维度验证\n",
    "print(\"=\"*50)\n",
    "print(f\"编码器输入（x）维度：{x.shape} → [4,20]\")\n",
    "print(f\"解码器输入（target）维度：{target.shape} → [4,18]\")\n",
    "print(f\"编码器PAD掩码维度：{input_padding_mask.shape} → [4,20]\")\n",
    "print(f\"注意力掩码（target_mask）维度：{target_mask.shape} → [18,18]\")\n",
    "print(f\"记忆掩码（input_target_mask）维度：{input_target_mask.shape} → [4,18,20]\")\n",
    "print(f\"Transformer输出维度：{output.shape} → 预期[4,18,16]\")\n",
    "print(f\"特征映射到词表后的最终输出维度：{fc_out.shape} → 预期 [4, 18, 10]\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 6. 验证参数设备\n",
    "print(f\"模型设备：{next(transformer.parameters()).device}\")\n",
    "print(f\"输出设备：{output.device}\")\n",
    "# 查看参数数量 81930\n",
    "total_params = sum(p.numel() for p in transformer.parameters())\n",
    "print(f\"\\n总参数数：{total_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76479c9-1583-4654-9f88-cd5063964cda",
   "metadata": {},
   "source": [
    "### 测试手动的Transformer训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "a47215d8-2eda-47cb-8d88-7d362589523e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#可视化\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "667b4f68-eff4-4c96-a808-bec18c92e70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练进度: 100%|██████████| 100/100 [00:06<00:00, 16.24it/s, Loss=0.0905]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 核心配置: 设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"device = {device}\")\n",
    "\n",
    "# 0.设置参数   同最开始的\n",
    "d_model = 64                  #模型特征维度\n",
    "num_heads = 8                 #多头数\n",
    "batch_size = 8                #一个批次的大小\n",
    "ffn_dim = 2048                #前馈网络特征维度\n",
    "dropout = 0.1                 #丢弃率\n",
    "num_layers = 6                #编码器和解码器的层数\n",
    "sequence_length = 10          #序列长度\n",
    "max_len = sequence_length     #最大序列长度，最好=序列长度\n",
    "vocab_size = 10               #词表大小（语言类用）\n",
    "target_seq_length = 10        #目标序列长度\n",
    "\n",
    "epochs = 100                  # 训练轮数\n",
    "lr = 1e-3                     # 学习率\n",
    "pad_idx = 0                   # PAD token索引（损失函数忽略）\n",
    "\n",
    "input = kokomi_input.to(device)     #和最前面的 玩一下 同一个输入\n",
    "target = kokomi_target.to(device)   #和最前面的 玩一下 同一个输入\n",
    "\n",
    "model = Transformer(\n",
    "    d_model=d_model, num_heads=num_heads, ffn_dim=ffn_dim,\n",
    "    num_layers=num_layers, vocab_size=vocab_size, max_len=max_len, dropout=dropout\n",
    ").to(device)\n",
    "\n",
    "# 损失函数：CrossEntropyLoss（忽略PAD token）\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器：Adam（Transformer经典优化器）\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "model.train()  # 切换训练模式\n",
    "\n",
    "# 记录Loss变化\n",
    "train_losses = []\n",
    "pbar = tqdm(range(epochs), desc=\"训练进度\")\n",
    "\n",
    "for epoch in pbar:\n",
    "    optimizer.zero_grad()  # 清空梯度\n",
    "\n",
    "    target_new = target[:, :-1]  # Decoder输入：[8,9]  少了一位\n",
    "    # target_target = target[:, 1:]  # Loss计算目标：[8,9]\n",
    "    \n",
    "    target_mask = generate_square_subsequent_mask(target_seq_length-1, device)  # [18,18]\n",
    "    # input_target_mask = generate_input_target_mask(input_padding_mask, target_seq_length, device)  # [4,18,20]\n",
    "\n",
    "    # 前向传播\n",
    "    output, fc_out = model(input, target_new, target_mask, input_target_mask=None)\n",
    "\n",
    "    # 计算Loss（调整维度：[batch, seq_len, vocab] → [batch*seq_len, vocab]）\n",
    "    loss = criterion(\n",
    "        fc_out.reshape(-1, vocab_size),  \n",
    "        target[:, 1:].reshape(-1)        \n",
    "    )\n",
    "\n",
    "    # 反向传播 + 梯度裁剪 + 优化\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    pbar.set_postfix({\"Loss\": f\"{loss.item():.4f}\"})\n",
    "    # 记录Loss\n",
    "    train_losses.append(loss.item())\n",
    "\n",
    "    # # 5. 保存模型（可选）\n",
    "    # torch.save(model.state_dict(), 'transformer_model.pth')\n",
    "    # print(\"\\n✅ 训练完成！模型已保存为 transformer_model.pth\")\n",
    "\n",
    "# 4. 可视化Loss变化\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Transformer Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720c075c-d6a4-463e-a96f-cece68cd8eac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
